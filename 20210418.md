####参考
##### [https://cloud.tencent.com/developer/article/1613107](https://cloud.tencent.com/developer/article/1613107)
https://www.elastic.co/guide/en/elasticsearch/guide/2.x/near-real-time.html
https://www.elastic.co/guide/en/elasticsearch/guide/2.x/merge-process.html

**1、数据存储可靠性保证原理**

1.1 translog机制

######写入时可能会丢失数据的场景：
当一个文档写入Lucence后是存储在内存中的，即使执行了refresh操作仍然是在文件系统缓存中，如果此时服务器宕机，那么这部分数据将会丢失

######引入translog：
当进行文档写操作时会先将文档写入Lucene，然后写入一份到translog，写入translog是落盘的

tips:如果对可靠性要求不是很高，也可以设置异步落盘，可以提高性能，由配置index.translog.durability和index.translog.sync_interval控制
tips:translog是追加写入，因此性能比较好

######写入顺序：
先写入Lucene再写入translog。原因是写入Lucene可能会失败，为了减少写入失败回滚的复杂度，因此先写入Lucene

1.2 flush操作

![flush操作流程](https://upload-images.jianshu.io/upload_images/26104743-f8fe32bb16473668.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
refresh_interval定时触发 或当translog达到index.translog.flush_threshold_size（默认512mb)，ES会触发一次flush操作：先执行refresh操作将buffer中的数据生成segment，然后调用lucene的commit方法将所有内存中的segment fsync到磁盘，最后会清空translog中的数据(6.x版本为了实现sequenceIDs，不删除translog) 。

```
// Perhaps you are using Elasticsearch to index millions of log files, and you would prefer to optimize for index speed rather than near real-time search. You can reduce the frequency of refreshes on a per-index basis
PUT /my_logs
{"settings": 
  {
    "refresh_interval": "30s"   //Refresh the my_logs index every 30 seconds.
  }
}
PUT /my_logs/_settings
{ "refresh_interval": -1 }  //Disable automatic refreshes.
```

1.3 merge操作
refresh操作会产生大量的小segment，因此产生的每个文件都会消耗文件句柄，内存，CPU 使用等各种资源。更重要的是每个查询请求都要顺序检查每个segment; segment越多检索会越慢.
ES会运行一个检测任务，在后台把近似大小的segment合并成一个新的大segment，并删除旧segment

1.4、多副本机制
ES有多副本机制（默认是1个副本），一个分片的主副分片不能分片在同一个节点上，进一步保证数据的可靠性。

**2、ES写索引的流程**
![写索引流程](https://upload-images.jianshu.io/upload_images/26104743-99e9c4abba9d26a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

1)	用户创建了一个新文档，新文档被写入内存中；

2)	refresh操作提交缓存，这时缓存中数据会以segment的形式被先写入到文件缓存系统。这是因为，提交一个新的segment到磁盘需要一个fsync 来确保segment被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是 fsync 操作代价很大，如果每次索引一个文档都去执行一次的话会造成很大的性能问题，但是这里新segment会被先写入到文件系统缓存，这一步代价会比较低；

3)	新的segment被写入到文件缓存系统，这时内存缓存被清空。在文件缓存系统会存在一个未提交的segment。虽然新segment未被commit（刷到磁盘），但是文件已经在缓存中了，此时就可以像其它文件一样被打开和读取了；

4)	到目前为止索引的segment还未被刷新到磁盘，如果没有用 fsync 把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。Elasticsearch 增加了一个 translog ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。如上图所示，一个文档被索引之后，就会被添加到内存缓冲区，并且同时追加到了 translog；

5)	每隔一段时间，更多的文档被添加到内存缓冲区和追加到事务日志（translog），之后新segment被不断从内存缓存区被写入到文件缓存系统，这时内存缓存被清空，但是事务日志不会。随着 translog 变得越来越大，达到一定程度后索引被刷新，在刷新（flush）之后，segment被全量提交（被写入硬盘）。






